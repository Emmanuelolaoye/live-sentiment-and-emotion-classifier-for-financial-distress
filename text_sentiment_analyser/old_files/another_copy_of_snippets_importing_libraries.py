# -*- coding: utf-8 -*-
"""Another copy of Snippets: Importing libraries

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UaAT05fSSvOHOekNaRICt47Qs0Pp4112
"""

import numpy as np
import torch
import scipy
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
# !pip install datasets
# !pip install evaluate
from datasets import load_dataset
import evaluate
from torch.utils.data import DataLoader

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

# Load the dataset
dataset = load_dataset("ugursa/Yahoo-Finance-News-Sentences")

# Split the dataset into training and evaluation sets using the datasets library
train_test_split = dataset["train"].train_test_split(test_size=0.2, seed=42)
train_dataset = train_test_split["train"]
eval_dataset = train_test_split["test"]

# Load the tokenizer
tokenizer = AutoTokenizer.from_pretrained("ProsusAI/finbert")

# Tokenize function
def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

# Tokenize the dataset
tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)
tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)

# Load the metric
metric = evaluate.load("accuracy")

# Compute metrics function
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)

# Load the model
model = AutoModelForSequenceClassification.from_pretrained("ProsusAI/finbert")
model.to(device)  # Move model to GPU if available

# Define training arguments
training_args = TrainingArguments(
    output_dir="../test_trainer",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    learning_rate=2e-5,
    weight_decay=0.01,
    logging_dir="../../saved_models/logs",
    logging_steps=10,
    save_total_limit=3,
    load_best_model_at_end=True,
)

# Initialize the Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_train_dataset,
    eval_dataset=tokenized_eval_dataset,
    compute_metrics=compute_metrics,
)

# Train the model
trainer.train()

# Save the fine-tuned model and tokenizer
model.save_pretrained("fine_tuned_model")
tokenizer.save_pretrained("fine_tuned_model")

# Evaluate the model
eval_dataloader = DataLoader(tokenized_eval_dataset, batch_size=16)



import torch

# def evaluate_model(model, dataloader):
#     model.eval()
#     all_predictions = []
#     all_labels = []
#     all_confidences = []

#     with torch.no_grad():
#         for batch in dataloader:
#             inputs = {key: value.to(device) for key, value in batch.items() if key != "labels"}
#             labels = batch["labels"].to(device)

#             outputs = model(**inputs)
#             logits = outputs.logits
#             predictions = torch.argmax(logits, dim=-1)

#             # Calculate confidence levels (softmax)
#             softmax = torch.nn.functional.softmax(logits, dim=-1)
#             confidences, _ = torch.max(softmax, dim=-1)

#             all_predictions.extend(predictions.cpu().numpy())
#             all_labels.extend(labels.cpu().numpy())
#             all_confidences.extend(confidences.cpu().numpy())

#     # Calculate accuracy
#     accuracy = np.mean(np.array(all_predictions) == np.array(all_labels))
#     # Calculate average confidence
#     avg_confidence = np.mean(all_confidences)

#     return accuracy, avg_confidence




# def evaluate_model(model, dataloader):
#     model.eval()
#     all_predictions = []
#     all_labels = []
#     all_confidences = []

#     with torch.no_grad():
#         for batch in dataloader:
#             # Convert list values to tensors

#             labels = batch["labels"].to(device)

#             outputs = model(**inputs)
#             logits = outputs.logits
#             predictions = torch.argmax(logits, dim=-1)

#             # Calculate confidence levels (softmax)
#             softmax = torch.nn.functional.softmax(logits, dim=-1)
#             confidences, _ = torch.max(softmax, dim=-1)

#             all_predictions.extend(predictions.cpu().numpy())
#             all_labels.extend(labels.cpu().numpy())
#             all_confidences.extend(confidences.cpu().numpy())

#     # Calculate accuracy
#     accuracy = np.mean(np.array(all_predictions) == np.array(all_labels))
#     # Calculate average confidence
#     avg_confidence = np.mean(all_confidences)

#     return accuracy, avg_confidence

# accuracy, avg_confidence = evaluate_model(model, eval_dataloader)
# print(f"Accuracy: {accuracy}")
# print(f"Average Confidence: {avg_confidence}")


import torch
import numpy as np

def evaluate_model(model, dataloader, device):
    model.eval()
    all_predictions = []
    all_labels = []
    all_confidences = []

    with torch.no_grad():
        for batch in dataloader:
            # Debug: Print batch keys
            print(f"Batch keys: {batch.keys()}")

            if "label" not in batch:
                raise KeyError("Batch does not contain 'label' key.")

            labels = batch["label"].to(device)

            # Move tensor-like inputs to device
            inputs = {}
            for k, v in batch.items():
                if k in ["input_ids", "attention_mask", "token_type_ids"]:
                    if isinstance(v, torch.Tensor):
                        inputs[k] = v.to(device)
                    else:
                        try:
                            # Convert list or numpy array to tensor
                            v = np.array(v)  # Convert list to numpy array first
                            inputs[k] = torch.tensor(v, dtype=torch.long).to(device)
                        except Exception as e:
                            print(f"Error converting {k} to tensor: {e}")
                            raise

            # Debug: Print inputs keys and shapes
            print(f"Inputs keys: {inputs.keys()}")
            for key, value in inputs.items():
                print(f"Shape of {key}: {value.shape}")

            # Ensure required keys are in the inputs
            if "input_ids" not in inputs:
                raise ValueError("Batch does not contain 'input_ids' key which is required for the model.")

            outputs = model(**inputs)
            logits = outputs.logits
            predictions = torch.argmax(logits, dim=-1)

            # Debug: Print shapes of logits and predictions
            print(f"Shape of logits: {logits.shape}")
            print(f"Shape of predictions: {predictions.shape}")
            print(f"Shape of labels: {labels.shape}")

            # Calculate confidence levels (softmax)
            softmax = torch.nn.functional.softmax(logits, dim=-1)
            confidences, _ = torch.max(softmax, dim=-1)

            all_predictions.extend(predictions.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_confidences.extend(confidences.cpu().numpy())

    # Debug: Print lengths of all_predictions and all_labels
    print(f"Length of all_predictions: {len(all_predictions)}")
    print(f"Length of all_labels: {len(all_labels)}")

    # Calculate accuracy
    accuracy = np.mean(np.array(all_predictions) == np.array(all_labels))
    # Calculate average confidence
    avg_confidence = np.mean(all_confidences)

    print(f"Accuracy: {accuracy}")
    print(f"Average Confidence: {avg_confidence}")

    return accuracy, avg_confidence

# Example usage:
# Assuming `model` and `eval_dataloader` are defined and `device` is set

accuracy, avg_confidence = evaluate_model(model, eval_dataloader, torch.device("cuda"))
print(f"Accuracy: {accuracy}")
print(f"Average Confidence: {avg_confidence}")

# Example usage:
# Assuming `model` and `eval_dataloader` are defined and `device` is set


accuracy, avg_confidence = evaluate_model(model, eval_dataloader, torch.device("cuda"))
print(f"Accuracy: {accuracy}")
print(f"Average Confidence: {avg_confidence}")